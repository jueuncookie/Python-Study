# -*- coding: utf-8 -*-
"""파이썬학습노트_포트폴리오.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1croKgpk33CzR6Agdrg6sNQt0i4OplmDz

#**Google Colaboratory**
## Google Colab 개요

## Google Colab 특징
*   구글 클라우드 기반의 무료 개발 환경 서비스
*   환경 설정 및 실행까지 매우 빠른 환경
*   딥러닝 실행이 가능한 정도의 고사양 환경을 제공
*   대부분의 패키지들이 이미 설치된 환경 제공
*   여러 사용자와 동시에 사용 가능
*   PC, 태블릿, 모바일 상관없이 인터넷 브라우저만 있으면 언제 어디서나 접속 가능
*   목차나 Makedown 미리보기 등 다양한 기능 제공
*   구글 드라이브와 연동 가능
*   Git이나 Github와 쉽게 연동 가능

## Google Colab 사양
*   플랫폼

```
import platform
platform.platform()
```
"""

import platform
platform.platform()

"""* 운영체제



```
!cat /etc/issue.net
```




"""

!cat /etc/issue.net

"""*   CPU 사양

```
!cat /proc/cpuinfo
```




"""

!cat /proc/cpuinfo  #my com말고 클라우드의cpu사양

"""

*   메모리 사양


```
!cat /proc/meminfo
```



"""

!cat /proc/meminfo

"""

*   파이썬 버전

```
!python --version
```



"""

!python --version

import pandas as pd
pd.__version__

"""## Google Colab 런타임

*   Colab에서 고성능 하드웨어로 GPU나 TPU 사용 가능
*   런타임 유형 변경 필요


**   None: CPU만 사용

**  GPU: 하드웨어 가속으로 GPU 사용

**   TPU: 하드웨어 가속으로 TPU 사용


```
!cat /proc/cpuinfo
```

##파일 저장 및 다운로드/업로드
*   Jupyter Notebook 환경에서 파일 저장 및 다운로드
```
%%writefile test.txt
text
```
```
!cat test.txt
```
```
from google.colab import files
files.download('test.txt')
```
```
upload = files.upload()
```
```
!ls
```
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile test.txt 
# text
#  #파일 만들기

!cat test.txt # 파일 제대로 만들었는지 확인

!ls #파일 올라갔는지 확인

"""## Google Drive 연동
*   Google Colab은 Google Drive와 mount를 통해 쉽게 연동 가능


```
from google.colab import drive
drive.mount('/content/drive')
```
** 인증코드 복사 

*   Google Drive에 소스 코드 저장뿐만 아니라 파일을 열거나 저장 가능


```
!ls /content/drive
```



"""

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive #drive에 있는 내용을 보겠다!!!!!!

"""---

#공공데이터 EDA(Exploratory Data Analysis: 탐색적 자료 분석)

## 개요


*   어떤 직무에서든 필요
*   실무 응용
 
*   2가지 목적 - 잘 분석하기 위한 전처리, raw data의 특성 파악

## 라이브러리 및 데이터
"""

import pandas as pd #판다스 패키지 불러오기

"""- pandas는 데이터를 불러오고, 전처리에 사용되는 Python 라이브러리
- Anaconda를 설치할 때 함께 설치
"""

!pip list
!pip install pandas
import pandas as pd

"""### pd.read_csv()


*   csv파일 읽는 함수


"""

#csv 패키지로 읽어오는 방법
import csv
file_name = '/content/sample_data/california_housing_train.csv'
with open(file_name) as csvfile:
  line = csv.reader(csvfile)
  i = 0
  for In in line:
    print(In)
    i = i + 1
    if i == 10:
      break

#pandas 패키지로 읽어오는 방ㅂ버
import pandas as pd
file_name = '/content/sample_data/california_housing_train.csv'
line = pd.read_csv(file_name)
line.head(10)

"""[전국 신규 민간 아파트 분양가격 동향](https://www.data.go.kr/data/3035522/fileData.do)

### Excel에서 테스트
"""

import pandas as pd

line = pd.read_csv('/content/sample_data/california_housing_train.csv', encoding='949')

line.head(10)

line.head()

line.head(2)

"""[StackOverflow](https://stackoverflow.com/)

## 다른 공공데이터 활용

# 웹 스크래핑 vs 웹 크롤링


*   웹 페이지에서 내가 원하는 부분만 추출
*   웹 페이지 링크를 따라가며 데이터 수집
*   HTML (Hyper Text Markup Language) 이해
*   xPath 이해
*   크롬 웹 브라우저 활용 (크롬 설치)

- 크롬에서 네이버 오픈 -> 특정 엘리먼트에서 마우스 우클릭 -> 검사 명령어 실행 (단축키 F12)

- 개발자도구에서 화면 왼쪽 상단 첫번째 아이콘 클릭 후 탐색

- 특정 엘리먼트에서 마우스 우클릭 -> Copy -> Copy XPath -> 주소창에 클릭하여 테스트

- 특정 엘리먼트에서 마우스 우클릭 -> Copy -> Copy full XPath -> 주소창에 클릭하여 테스트

- requests
"""

import requests
res = requests.get('http://naver.com')

import requests
res = requests.get('http://naver.com')
res.status_code #200이면 정상

import requests
res = requests.get('http://ecampus.konkuk.ac.kr/ilos/main/main_form.acl')
res.status_code #200이면 정상, 403이면 접근권한이 없음

len(res.text)

import requests
res = requests.get('https://wein.konkuk.ac.kr/common/user/login.do?rtnUrl=8f4d222b9b8edea9acd345835aea594efbe2fd91b58f38dc7634e924e73e51ad')
res.status_code #200이면 정상, 403이면 접근권한이 없음
#res.raise_for_status()

# 접속한 이후의 웹 사이트 소스코드를 추출
html = res.text.strip()

print(html)

"""## 정규식 (re: regular expression)
- 주민등록번호
- 이메일 주소
- 차량번호
- ip 주소
"""

import re

r = re.compile('a.c')
r.search("abc")

"""- .은 한 개의 임의의 문자를 나타냄 
- 정규 표현식 a.c
- a와 c 사이에 어떤 1개의 문자가 올 수 있음 
- akc, azc, avc, a5c, a!c와 같은 형태
- 모두 a.c의 정규 표현식과 매치
"""

r = re.compile('a.c')
r.search("akk")

"""- ?는 ? 앞의 문자가 존재할 수도 있고, 존재하지 않을 수도 있는 경우
- 정규 표현식이 ab?c
- 이 경우 이 정규 표현식에 b는 있다고 취급할 수도, 없다고 취급할 수도 있음
- abc와 ac 모두 매치

[w3schools](https://www.w3schools.com/python/default.asp)

- Python RegEx

## beautifulsoup
-  HTML 및 XML 파일에서 데이터를 가져 오기위한 Python 라이브러리

## lxml
- Python 언어로 XML 및 HTML을 처리하기위한 파서(구문 분석)
"""

import requests
from bs4 import BeautifulSoup

url = 'https://comic.naver.com/webtoon/weekday.nhn'
res = requests.get(url)
res.raise_for_status()

soup = BeautifulSoup(res.text, 'lxml')
print(soup.title)

print(soup.title.get_text())

print(soup.a)

print(soup.a.attrs)

print(soup.a['href'])

"""- soup.find('a')
- 페이지에 대한 정보를 잘 모를 때 사용
- 전반적인 HTML 태그와 엘리먼트에 대한 지식이 필요

- 웹 스크래핑 후 CSV 파일로 저장하기
- 네이버에서 코스피 시가총액 순위
"""

import csv
import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://finance.naver.com/sise/sise_market_sum.nhn'


res = requests.get(url)
res.raise_for_status()
soup = BeautifulSoup(res.text, 'lxml')

print(soup)

import pandas as pd

url ='https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%ED%99%98%EC%9C%A8%EC%A1%B0%ED%9A%8C'

tables= pd.read_html(url)

tables

len(tables)

tables[0]

df = tables[0]

df

df.loc[0]

df.iloc[1]

df.to_csv('kospi.csv')

x = pd.read_csv('kospi.csv')

x.head(10)

df.to_excel('exchange rate.xlsx')

x = pd.read_excel('exchange rate.xlsx')

x.head(10)

"""---

**3주차 수업 때 부연설명**
"""

import pandas as pd
x = pd.read_csv('kospi.csv', index_col='통화명')
print(x.shape)
x.head()

import pandas as pd
x = pd.read_excel('exchange rate.xlsx', index_col='통화명')
print(x.shape)
x.head()

"""# pandas 기본문법

### Series 
- 1차원 배열, 복수의 행과 하나의 열로 구성하며 인덱스로 원하는 데이터에 접근
*   Data Frame #2차원 배열
"""

import pandas as pd

pd.Series([7, 3, 5, 8])

x = pd.Series(data=[7, 3, 5, 8], index=['서울', '대구', '부산', '광주'])

print(x)

pd.Series([7, 3, 5, 8], index=['서울', '대구', '부산', '광주'])

x[[0,1]]

x['서울']



x[['서울', '대구']]

x.index

x.values

print(sorted(x.index)) #ㄱㄴㄷㄹ로

print(sorted(x.values)) #오름차순

x=pd.Series([3, 8, 5, 9], index=['서울', '대구', '부산', '광주'])
y=pd.Series([2, 4, 5, 1], index=['대구', '부산', '서울', '대전'])    #NaN(Not a Number), 공통된 인덱스가 존재해야 수식 가능

x+y

model = [1, 3, 2, 4, 2, 3]
x = pd.Series(model)

x.unique()

pd.unique(x)

model = ['민준', '현우', '서연', '동현', '서연', '현우']
x = pd.Series(model)

pd.unique(x)

age = {'민준':23, '현우':43, '서연':12, '동현':45} #민준이 키, 23이 값. 각 키와 값으로 구성된 것은 dictionary

x = pd.Series(age)

x

import pandas as pd

names = ['민준', '서연', '현우', '민서', '동현', '수빈']

pdata = pd.Series(names)

print(pdata)

a = pdata[3:7]  #끝자리는 하나가 작은 수까지 나옴  3~6까지

print(a[2])  #a 구간에선 2라는 인덱스가 없다 -> 오류 원인

a = pdata[2:4]  #2~3
a

a = pdata[0:6]  
a

print(a[2])

print(a)

"""***판다스 기본 문법 추가 정리*** """

pd.__version__

series = pd.Series(['a', 'b', 'c'])

series[2]

series = pd.Series(['a', 'b', 'c'], index=[3, 2, 3])

import pandas as pd
series = pd.Series(['a', 'b', 'c'], index=[3, 2, 3])

series.index

series[2]

series[3]

series[-1] #음수 인덱스는 에러 발생

"""### Data Frame 
- 2차원 배열
- 샘플데이터
[KBO 기록실](https://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx)
"""

import pandas as pd

url ='https://www.koreabaseball.com/Record/Player/HitterBasic/BasicOld.aspx?sort=HRA_RT'

tables = pd.read_html(url)

len(tables)

tables[0]

df = tables[0]
df['팀명']

df['팀명'].iloc[0]

df['팀명'].loc[0]

df['가족 수']=[1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,1,1,2,3,4,5,6,7,8,9,10,1,2,3]
df

pd.unique(df['팀명'])

df['팀명'].unique()

df['팀명'].nunique()

df[['선수명','팀명']]

df[['선수명','팀명','AVG']]

pd.value_counts(df['AVG']>0.32)

"""[수비 기록 데이터 출처](https://www.koreabaseball.com/Record/Player/Defense/Basic.aspx)"""

import pandas as pd

url ='https://www.koreabaseball.com/Record/Player/Defense/Basic.aspx'

tables = pd.read_html(url)

len(tables)

df = tables[0]
df

df = df[['선수명','팀명','POS', 'FPCT']]
df

df['선수명'].nunique()

df['팀명'].nunique()

"""**4주차 리포트**

Pandas 문법 정리해 보기, 수업 시간에 다루지 않은 문법 3개 다루어 추가하기

***4주차 수업에 부여 설명***
, 5주차 영상에 포함
"""

df = pd.DataFrame([
              [100, 230, 90],
              [140, 150, 40],
              [110, 100, 50],
])

df

df[1]

df.loc[1]

df.iloc[1]

df[3] = [200, 210, 220]

df

"""---

# Excel 파일을 DataFrame으로 만들기
"""

df = pd.read_excel('score.xlsx')
print(df.shape)

df.head()

df = pd.read_excel('score2.xlsx')
print(df.shape)

df.head()

df['철수'] + df['영희'] + df['잡스']

df['철수'] + df['영희'] + df['잡스']

df.to_excel('score_result.xlsx')

"""***5주차 수업에 부연설명***



"""

import numpy as np

data = np.random.rand(3,5)
data

from matplotlib import pyplot as plt

x = [0, 1, 2, 3]
y = [1, 4, 9, 16]

plt.plot(x, y)
plt.title("Line Plot")
plt.xlabel("X 축")
plt.ylabel("Y 축")
plt.show()

# 나눔고딕 설치
!apt -qq -y install fonts-nanum > /dev/null

import matplotlib.font_manager as fm

fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'
font = fm.FontProperties(fname=fontpath, size=9)
fm._rebuild()

# 그래프에 retina display 적용
#%config InlineBackend.figure_format = 'retina'

# Colab 의 한글 폰트 설정
plt.rc('font', family='NanumBarunGothic')

"""- 코랩의 주석 처리 단축키 ctrl + / 
- 주석 처리하고자 하는 글들을 드래그 한 후에 단축키 입력
- 주석 해제할 때도 동일하게 ctrl + /  
"""

x = [0, 1, 2, 3]
y = [1, 4, 9, 16]

plt.plot(x, y)
plt.title("Line Plot")
plt.xlabel("X 축")
plt.ylabel("Y 축")
plt.show()

x = [0, 1, 2, 3]
y = [1, 4, 9, 16]

plt.figure(figsize=(10, 5))
#plt.figure(figsize=(1, 1))

plt.plot(x, y)
plt.title("Line Plot")
plt.xlabel("X 축")
plt.ylabel("Y 축")
plt.show()

#plt.grid()

import pandas as pd

x = [0, 1, 2, 3]
y = [1, 4, 9, 16]

df = pd.DataFrame(y, index = x)
df

df.plot()

df.plot(title = "Line Plot", figsize = (10, 5), grid = True)

ax = df.plot(title = "Line Plot", figsize = (10, 5), grid = True)

ax.set_xlabel("X 축")
ax.set_ylabel("Y 축")

"""---"""